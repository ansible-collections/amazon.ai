- name: Amazon Bedrock Inference integration tests
  module_defaults:
    group/amazon.ai.aws:
      access_key: "{{ aws_access_key }}"
      secret_key: "{{ aws_secret_key }}"
      session_token: "{{ security_token | default(omit) }}"
      region: "{{ aws_region }}"
  block:
    - name: List all foundation models without filters
      amazon.ai.bedrock_foundation_models_info:
      register: list_all_result

    - name: The task ran successfully and returned a list
      ansible.builtin.assert:
        that:
          - list_all_result is success
          - not list_all_result is changed
          - list_all_result.model_summaries is defined
          - list_all_result.model_summaries | length > 0
        msg: "The bedrock_foundation_models_info task failed or did not return a valid list."

    - name: List models filtered by provider 'Anthropic'
      amazon.ai.bedrock_foundation_models_info:
        by_provider: 'Anthropic'
      register: list_anthropic_result

    - name: Assert that all models in the list are from the 'Anthropic' provider
      ansible.builtin.assert:
        that:
          - list_anthropic_result.model_summaries | selectattr('provider_name', 'equalto', 'Anthropic') | list | length == list_anthropic_result.model_summaries | length
        msg: "The list contains models from other providers, which is incorrect."

    - name: Extract an on-demand 'Claude' model ID
      ansible.builtin.set_fact:
        claude_model_summary: >-
          {{ list_anthropic_result.model_summaries
            | selectattr('model_name', 'equalto', 'Claude')
            | selectattr('inference_types_supported', 'contains', 'ON_DEMAND')
            | first }}

    - name: Assert that a valid 'Claude' on-demand model was found
      ansible.builtin.assert:
        that:
          - claude_model_summary is defined
          - claude_model_summary.model_id is defined
          - "'ON_DEMAND' in claude_model_summary.inference_types_supported"
        msg: "Could not find an on-demand Claude 3 Haiku model. Your AWS account may not have access."

    - name: Extract a model_id from the filtered list
      ansible.builtin.set_fact:
        model_id: "{{ claude_model_summary.model_id }}"

    - name: Invoke the Bedrock model with a simple prompt
      amazon.ai.bedrock_inference:
        model_id: "{{ model_id }}"
        prompt: "{{ test_prompt }}"
      register: inference_result

    - name: Assert the task ran successfully
      ansible.builtin.assert:
        that:
          - inference_result is success
          - inference_result is changed
        msg: "The bedrock_inference task did not succeed or did not report a change."

    - name: Assert the returned completion is a non-empty string
      ansible.builtin.assert:
        that:
          - inference_result.completion is defined
          - inference_result.completion is string
          - inference_result.completion | length > 0
        msg: "The completion text was not returned or was empty."

    - name: Assert the returned values match the input
      ansible.builtin.assert:
        that:
          - inference_result.model_id == test_model_id
          - inference_result.prompt == test_prompt
        msg: "The returned model_id or prompt did not match the input."
